# AdaDetectGPT

[![NeurIPS 2025](https://img.shields.io/badge/NeurIPS-2025-blue)](https://neurips.cc/)  <!-- NeurIPS 2025ä¼šè®®è®ºæ–‡ -->
[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-green)](https://www.python.org/)  <!-- Pythonç‰ˆæœ¬è¦æ±‚ -->

This repository contains the implementation of [**AdaDetectGPT: Adaptive Detection of LLM-Generated Text with Statistical Guarantees**](https://arxiv.org/abs/2510.01268), presented at NeurIPS 2025. Our method provides adaptive detection of LLM-generated text with statistical guarantees. We build upon and extend code from [Fast-DetectGPT](https://github.com/baoguangsheng/fast-detect-gpt).

æœ¬ä»“åº“åŒ…å«åœ¨NeurIPS 2025ä¼šè®®ä¸Šå‘è¡¨çš„è®ºæ–‡**AdaDetectGPT**çš„å®ç°ï¼Œè¯¥æ–¹æ³•æä¾›å…·æœ‰ç»Ÿè®¡ä¿è¯çš„è‡ªé€‚åº”LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºå¹¶æ‰©å±•äº†[Fast-DetectGPT](https://github.com/baoguangsheng/fast-detect-gpt)çš„ä»£ç ã€‚

## ğŸ“‹ Overview
## ğŸ“‹ æ¦‚è¿°

![AdaDetectGPT Workflow](figure/AdaDetectGPT.png)

Workflow of **AdaDetectGPT**. Built upon Fast-DetectGPT (Bao et al., 2024), our method adaptively learn a witness function $\hat{w}$ from training data by maximizing a lower bound on the TNR, while using normal approximation for FNR control.

**AdaDetectGPT**çš„å·¥ä½œæµç¨‹ï¼šåŸºäºFast-DetectGPT (Bao et al., 2024)ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡æœ€å¤§åŒ–TNRï¼ˆçœŸé˜´æ€§ç‡ï¼‰ä¸‹ç•Œæ¥è‡ªé€‚åº”åœ°ä»è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ è§è¯å‡½æ•°$\hat{w}$ï¼ŒåŒæ—¶ä½¿ç”¨æ­£æ€è¿‘ä¼¼æ¥æ§åˆ¶FNRï¼ˆå‡é˜´æ€§ç‡ï¼‰ã€‚

## ğŸ› ï¸ Installation
## ğŸ› ï¸ å®‰è£…

### Requirements
### ç³»ç»Ÿè¦æ±‚
- Python 3.10.8  <!-- Pythonç‰ˆæœ¬è¦æ±‚ -->
- PyTorch 2.7.0  <!-- PyTorchæ¡†æ¶è¦æ±‚ -->
- CUDA-compatible GPU (experiments conducted on H20-NVLink with 96GB memory)  <!-- CUDAå…¼å®¹GPUè¦æ±‚ -->

### Setup
### å®‰è£…æ­¥éª¤
```bash
bash setup.sh  # æ‰§è¡Œå®‰è£…è„šæœ¬
```

*Note: While our experiments used high-memory GPUs, typical usage of AdaDetectGPT requires significantly less memory.*

*æ³¨æ„ï¼šè™½ç„¶æˆ‘ä»¬çš„å®éªŒä½¿ç”¨äº†é«˜å†…å­˜GPUï¼Œä½†AdaDetectGPTçš„å…¸å‹ä½¿ç”¨åœºæ™¯æ‰€éœ€å†…å­˜è¦å°‘å¾—å¤šã€‚*

## ğŸ’» Usage
## ğŸ’» ä½¿ç”¨æ–¹æ³•

### With Training Data (Recommended)
### ä½¿ç”¨è®­ç»ƒæ•°æ®ï¼ˆæ¨èï¼‰

For optimal performance, we recommend using training data. The training dataset should be a `.json` file named `xxx.raw_data.json` with the following structure:

ä¸ºè·å¾—æœ€ä½³æ€§èƒ½ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨è®­ç»ƒæ•°æ®ã€‚è®­ç»ƒæ•°æ®é›†åº”ä¸º`.json`æ ¼å¼çš„æ–‡ä»¶ï¼Œå‘½åä¸º`xxx.raw_data.json`ï¼Œå…·æœ‰ä»¥ä¸‹ç»“æ„ï¼š

```json
{
  "original": ["human-text-1", "human-text-2", "..."],  // äººç±»æ’°å†™çš„æ–‡æœ¬æ ·æœ¬
  "sampled": ["machine-text-1", "machine-text-2", "..."]   // LLMç”Ÿæˆçš„æ–‡æœ¬æ ·æœ¬
}
```

Run detection with training data:
ä½¿ç”¨è®­ç»ƒæ•°æ®è¿è¡Œæ£€æµ‹ï¼š
```bash
python scripts/local_infer_ada.py \
  --text "Your text to be detected" \
  --train_dataset "train-data-file-name"  ## å¤šä¸ªè®­ç»ƒæ•°æ®é›†ç”¨&åˆ†éš”
```

A quick example is: 
å¿«é€Ÿç¤ºä¾‹ï¼š
```bash
python scripts/local_infer_ada.py \
  --text "Your text to be detected" \
  --train_dataset "./exp_gpt3to4/data/essay_claude-3-5-haiku&./exp_gpt3to4/data/xsum_claude-3-5-haiku"
```

### Without Training Data
### ä¸ä½¿ç”¨è®­ç»ƒæ•°æ®

AdaDetectGPT can also use pretrained parameters (trained on texts from GPT-4o, Gemini-2.5, and Claude-3.5):

AdaDetectGPTä¹Ÿå¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒå‚æ•°ï¼ˆè¿™äº›å‚æ•°åœ¨GPT-4oã€Gemini-2.5å’ŒClaude-3.5ç”Ÿæˆçš„æ–‡æœ¬ä¸Šè®­ç»ƒï¼‰ï¼š

```bash
python scripts/local_infer_ada.py --text "Your text to be detected"  # ä½¿ç”¨é¢„è®­ç»ƒå‚æ•°è¿›è¡Œæ£€æµ‹
```

## ğŸ”¬ Reproducibility
## ğŸ”¬ å®éªŒå¤ç°

We provide generated text samples from GPT-3.5-Turbo, GPT-4, GPT-4o, Gemini-2.5, and Claude-3.5 in `exp_gpt3to4/data/` for convenient reproduction. Data from GPT-3.5-Turbo and GPT-4 are sourced from [Fast-DetectGPT](https://github.com/baoguangsheng/fast-detect-gpt).

æˆ‘ä»¬åœ¨`exp_gpt3to4/data/`ç›®å½•ä¸­æä¾›äº†æ¥è‡ªGPT-3.5-Turboã€GPT-4ã€GPT-4oã€Gemini-2.5å’ŒClaude-3.5çš„ç”Ÿæˆæ–‡æœ¬æ ·æœ¬ï¼Œæ–¹ä¾¿å¤ç°å®éªŒã€‚GPT-3.5-Turboå’ŒGPT-4çš„æ•°æ®æ¥è‡ª[Fast-DetectGPT](https://github.com/baoguangsheng/fast-detect-gpt)ã€‚

### Experiment Scripts
### å®éªŒè„šæœ¬

#### White-box Experiments
#### ç™½ç›’å®éªŒ
- `./exp_whitebox.sh` - Table 1: Evaluation on 5 base LLMs
  - GPT-2 (1.5B), GPT-Neo (2.7B), OPT-2.7B, GPT-J (6B), GPT-NeoX (20B)
  - å¯¹5ä¸ªåŸºç¡€LLMçš„è¯„ä¼°

- `./exp_whitebox_advanced.sh` - Table S7: Advanced open-source LLMs
  - Qwen-2.5 (7B), Mistral (7B), Llama3 (8B)
  - å¯¹é«˜çº§å¼€æºLLMçš„è¯„ä¼°

#### Black-box Experiments
#### é»‘ç›’å®éªŒ
- `./exp_blackbox_advanced.sh` - Table 2 and Table S8: Advanced closed-source LLMs
  - Gemini-2.5-Flash, GPT-4o, Claude-3.5-Haiku
  - å¯¹é«˜çº§é—­æºLLMçš„è¯„ä¼°

- `./exp_blackbox_simple.sh` - Table S2: Five open-source LLMs
  - å¯¹5ä¸ªå¼€æºLLMçš„è¯„ä¼°

#### Analysis Experiments
#### åˆ†æå®éªŒ
- `./exp_attack.sh` - Table 3: Adversarial attack evaluation
  - å¯¹æŠ—æ”»å‡»è¯„ä¼°

- `./exp_normal.sh` - Data for Figure 3 and Figure S8
  - ç”Ÿæˆå›¾3å’Œå›¾S8çš„æ•°æ®

- `./exp_sample.sh` - Training data size effects (Figure S5)
  - è®­ç»ƒæ•°æ®å¤§å°çš„å½±å“

- `./exp_tuning.sh` - Hyperparameter robustness (Figure S6)
  - è¶…å‚æ•°é²æ£’æ€§

- `./exp_dist_shift.sh` - Distribution shift analysis (Figure S7)
  - åˆ†å¸ƒåç§»åˆ†æ

- `./exp_compute.sh` - Computational cost analysis (Table S9 and S10)
  - è®¡ç®—æˆæœ¬åˆ†æ

- `./exp_variance.sh` - Equal variance condition verification (Table S5)
  - ç­‰æ–¹å·®æ¡ä»¶éªŒè¯

## ğŸ Additional Resources
## ğŸ å…¶ä»–èµ„æº

The `scripts/` directory contains implementations of various LLM detection methods from the literature. These implementations are modified from their official versions or the repo of [FastDetectGPT](https://github.com/baoguangsheng/fast-detect-gpt) to provide:
- Consistent input/output formats
- Simplified method comparison

`scripts/`ç›®å½•åŒ…å«äº†æ–‡çŒ®ä¸­å„ç§LLMæ£€æµ‹æ–¹æ³•çš„å®ç°ã€‚è¿™äº›å®ç°æ˜¯ä»å®˜æ–¹ç‰ˆæœ¬æˆ–[FastDetectGPT](https://github.com/baoguangsheng/fast-detect-gpt)çš„ä»“åº“ä¿®æ”¹è€Œæ¥ï¼Œæä¾›äº†ï¼š
- ä¸€è‡´çš„è¾“å…¥/è¾“å‡ºæ ¼å¼
- ç®€åŒ–çš„æ–¹æ³•æ¯”è¾ƒ

The provided methods are summarized below.

ä¸‹è¡¨æ€»ç»“äº†æä¾›çš„æ–¹æ³•ï¼š

| Method | Script File | Paper/Website |
|--------|------------|---------------|
| **AdaDetectGPT** | `detect_gpt_ada.py` | [arXiv:2510.01268](https://arxiv.org/abs/2510.01268) |
| **Binoculars** | `detect_binoculars.py` | [arXiv:2401.12070](https://arxiv.org/abs/2401.12070) |
| **BiScope** | `detect_biscope.py` | [NeurIPS 2024](https://neurips.cc/virtual/2024/poster/95814) |
| **DetectGPT** | `detect_gpt.py` | [arXiv:2301.11305](https://arxiv.org/abs/2301.11305) |
| **DetectLLM** | `detect_llm.py` | [arXiv:2306.05540](https://arxiv.org/abs/2306.05540) |
| **DNA-GPT** | `detect_gpt_dna.py` | [arXiv:2305.17359](https://arxiv.org/abs/2305.17359) |
| **Fast-DetectGPT** | `detect_gpt_fast.py` | [arXiv:2310.05130](https://arxiv.org/abs/2310.05130) |
| **GLTR** | `detect_gltr.py` | [arXiv:1906.04043](https://arxiv.org/abs/1906.04043) |
| **ImBD** | `detect_ImBD.py` | [arXiv:2412.10432](https://arxiv.org/abs/2412.10432) |
| **GPTZero** | `detect_gptzero.py` | [GPTZero.me](https://gptzero.me/) |
| **RADAR** | `detect_radar.py` | [arXiv:2307.03838](https://arxiv.org/abs/2307.03838) |
| **RoBERTa OpenAI Detector** | `detect_roberta.py` | [arXiv:1908.09203](https://arxiv.org/abs/1908.09203) |
| **Text Fluoroscopy** | `detect_fluoroscopy.py` | [EMNLP 2024](https://aclanthology.org/2024.emnlp-main.885/) |

We hope these resources facilitate your research and applications in LLM-generated text detection!

æˆ‘ä»¬å¸Œæœ›è¿™äº›èµ„æºèƒ½ä¿ƒè¿›æ‚¨åœ¨LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ–¹é¢çš„ç ”ç©¶å’Œåº”ç”¨ï¼

## ğŸ“– Citation
## ğŸ“– å¼•ç”¨

If you find this work useful, please consider citing our paper:

å¦‚æœæ‚¨è§‰å¾—è¿™é¡¹å·¥ä½œæœ‰ç”¨ï¼Œè¯·è€ƒè™‘å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@inproceedings{zhou2025adadetect,
  title={AdaDetectGPT: Adaptive Detection of LLM-Generated Text with Statistical Guarantees},
  author={Hongyi Zhou and Jin Zhu and Pingfan Su and Kai Ye and Ying Yang and Shakeel A O B Gavioli-Akilagun and Chengchun Shi},
  booktitle={The Thirty-Ninth Annual Conference on Neural Information Processing Systems},
  year={2025}
}
```

## ğŸ“§ Contact
## ğŸ“§ è”ç³»æ–¹å¼

For any questions/suggestions/bugs, feel free to open an [issue](https://github.com/Mamba413/AdaDetectGPT/issues) in the repository.

å¦‚æœ‰ä»»ä½•é—®é¢˜/å»ºè®®/é”™è¯¯ï¼Œè¯·éšæ—¶åœ¨ä»“åº“ä¸­æ‰“å¼€[issue](https://github.com/Mamba413/AdaDetectGPT/issues)ã€‚